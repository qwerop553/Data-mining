trControl = cv_ctrl,
tuneLength = 15,
tuneGrid = hp_grid,
metric = "Spec",
importance = TRUE)
class_rf <- randomForest(class~., data=train_df)
library(ggRandomForests)
library(pdp)
class_vip <- varImp(class_rf)
install.packages("ggRandomForests")
install.packages("pdp")
library(ggRandomFOrests)
library(spdep)
vip(class_rf$finalModel, num_features=10L, width = 0.5, fill = "green3", color="green1")
library(vip)
install.packages("vip")
library(vip)
vip(class_rf$finalModel, num_features=10L, width = 0.5, fill = "green3", color="green1")
class_vip
?randomForest
predict(class_rf, test_df)
pred <- predict(class_rf, test_df)
table(pred, test_df$class)
confusionMatrix(table(pred, test_df$class))
class_vip <- varImp(class_rf)
# 전체 변수 중 50%만 사용하기로 함.
important_variable <- class_vip$importance %>% rownames_to_column("variable") %>%
top_n(10, wt=Yes) %>%
pull(variable)
class_vip <- varImp(class_rf)
# 전체 변수 중 50%만 사용하기로 함.
important_variable <- class_vip$importance %>% rownames_to_column("variable") %>%
top_n(10, wt=Yes) %>%
pull(variable)
# ----- offset -----
#rm(list=ls(all.names = TRUE))
library(tidyverse)
library(janitor)
library(ggridges)
library(cowplot)
library(caret)
library(tidypredict)
library(skimr)
library(Information)
library(car)
library(randomForest)
# ----- 1. 전처리 -----
f_v <- dir(pattern = 'homework', recursive = TRUE)
for(i in 1:length(f_v)){
.tb <- read.csv(f_v[i], stringsAsFactors = FALSE)
.tb <- .tb %>% clean_names()
.tb$date1 <- str_replace_all(.tb$date1, "[AM|PM]", "")
.tb$date1 <- as.POSIXct(strptime(.tb$date1, "%Y-%m-%d %H:%M"))
assign(paste0('table', i), .tb)
}
for(i in 1:length(f_v)){
.tb_name <- paste0('table', i)
.tb <- get(.tb_name)
.tb1 <- .tb[c(min(which(.tb$item == "집도과1")),
min(which(.tb$item == "마취방법(주)")),
min(which(.tb$item == "신체적상태")),
min(which(.tb$item == "수술구분")),
min(which(.tb$item == "수술(전) 진단명")),
min(which(.tb$item == "수술체위"))),]
.tb1 <- .tb1 %>% select(item, value1) %>% spread(item, value1)
.tb2 <- .tb[c(which(.tb$group %in% c( "Inhalational Agent",
"Intravenous Agent",
"V/S")),
which(.tb$item == "마취시작일시")),]
.tb2 <- .tb2 %>% arrange(date1, item)
.inhal <- .tb2[min(which(.tb2$group == 'Inhalational Agent')),]
.inhal <- cbind(.inhal, data.frame(type=c("inhal")))
.inhal <- .inhal %>% select(type, item) %>% spread(type, item)
.intra <- .tb2[min(which(.tb2$group == 'Intravenous Agent')),]
.intra <- cbind(.intra, data.frame(type=c("intra")))
.intra <- .intra %>% select(type, item) %>% spread(type, item)
.tb2 <- .tb2[1:(which(.tb2$item=="마취시작일시")-1),]
.tb2 <- .tb2[c(min(which(.tb2$item == "BIS")),
min(which(.tb2$item == "HR (BPM)")),
min(which(.tb2$item == "NBP-D(mmHg)")),
min(which(.tb2$item == "NBP-M(mmHg)")),
min(which(.tb2$item == "NBP-S(mmHg)")),
min(which(.tb2$item == "SPO2 (%)")),
min(which(.tb2$item == "TOF Count")),
min(which(.tb2$item == "TOF ratio(%)"))),]
.tb2 <- .tb2 %>% select(item, value1) %>% na.omit()
if(!("BIS" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="BIS", value1="<NA>"))
if(!("HR (BPM)" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="HR (BPM)", value1="<NA>"))
if(!("NBP-D(mmHg)" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="NBP-D(mmHg)", value1="<NA>"))
if(!("NBP-M(mmHg)" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="NBP-M(mmHg)", value1="<NA>"))
if(!("NBP-S(mmHg)" %in% .tb2$item)) tb2 <- rbind(.tb2, data.frame(item="NBP-S(mmHg)", value1="<NA>"))
if(!("SPO2 (%)" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="SPO2 (%)", value1="<NA>"))
if(!("TOF Count" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="TOF Count", value1="<NA>"))
if(!("TOF ratio(%)" %in% .tb2$item)) .tb2 <- rbind(.tb2, data.frame(item="TOF ratio(%)", value1="<NA>"))
.tb2 <- .tb2 %>% select(item, value1) %>% spread(item, value1)
.class <- data.frame(class=.tb$class[1])
assign(paste0(.tb_name, '_rslt'), cbind(.tb1, .tb2, .intra, .inhal, .class))
}
rslt <- data.frame()
for(i in 1:length(f_v)){
.rslt_name <- paste0("table", i, "_rslt")
rslt <- rbind(rslt, get(.rslt_name))
}
rslt <- rslt %>% clean_names()
rslt$bis <- as.integer(rslt$bis)
rslt$hr_bpm <- as.integer(rslt$hr_bpm)
rslt$nbp_d_mm_hg <- as.integer(rslt$nbp_d_mm_hg)
rslt$nbp_s_mm_hg <- as.integer(rslt$nbp_s_mm_hg)
rslt$nbp_m_mm_hg <- as.integer(rslt$nbp_m_mm_hg)
rslt$spo2_percent <- as.integer(rslt$spo2_percent)
rslt$tof_count <- as.integer(rslt$tof_count)
rslt$tof_ratio_percent <- as.integer(rslt$tof_ratio_percent)
rslt$class <- factor(rslt$class)
# ----- 2. 탐색적 데이터분석 -----
rslt$spo2_percent[rslt$spo2_percent==1100] <- 100 # 이상값 변환
rslt_list <- partition(skim(rslt))
y_p <- rslt %>%
ggplot(aes(x = class, fill = class)) +
geom_bar(alpha = 0.8) +
scale_fill_manual(values = c("gray", "red")) +
guides(fill = FALSE)
x_cont_p <- rslt %>%
select(class, rslt_list$numeric$skim_variable) %>%
gather(variable, value, -class) %>%
mutate(value = as.integer(value)) %>%
ggplot(aes(x = value, y = class, fill = class)) +
facet_wrap( ~ variable, scale = "free", ncol = 3) +
scale_fill_manual(values = c("gray", "red")) +
geom_density_ridges(alpha = 0.8) +
guides(fill = FALSE, color = FALSE)
plot_grid(y_p, x_cont_p, rel_widths = c(1,3))
x_cat_p <- rslt %>%
select(class, rslt_list$character$skim_variable, rslt_list$factor$skim_variable) %>%
gather(variable, value, -class) %>%
group_by(class) %>%
count(variable, value) %>%
ungroup() %>%
ggplot(data = ., aes(x=value, y=n, fill=class)) +
geom_col(position="dodge", width=0.7) +
facet_wrap(~variable, scale = "free", ncol = 4) +
scale_fill_manual(values = c("gray", "red")) +
guides(fill = FALSE, color = FALSE)
plot_grid(y_p, x_cat_p, rel_widths = c(1,3))
# ----- 3. 데이터 변환 -----
rslt$status1 <- factor(ifelse(rslt$신체적상태 == "1.전신질환이 없는 건강한 환자", 1, 0))
rslt$status2 <- factor(ifelse(rslt$신체적상태 == "2.경도나 중등도의 전신 질환이 있는 환자", 1, 0))
rslt$status3 <- factor(ifelse(rslt$신체적상태 == "3.일상 생활에 제약을 주는 고도의 전신 질환이 있는 환자", 1, 0))
rslt$신체적상태 <- NULL
rslt$cholecystitis <- factor(ifelse(str_detect(rslt$수술_전_진단명, "cholecystitis"), 1, 0))
rslt$acute <- factor(ifelse(str_detect(rslt$수술_전_진단명, "[a|A]cute"), 1, 0))
rslt$gb <- factor(ifelse(str_detect(rslt$수술_전_진단명, "[gallbladder|GB]"), 1, 0))
rslt$polyp <- factor(ifelse(str_detect(rslt$수술_전_진단명, "Polyp"), 1, 0))
rslt$adenomyomatosis <- factor(ifelse(str_detect(rslt$수술_전_진단명, "adenomyomatosis"), 1, 0))
rslt$cancer <- factor(ifelse(str_detect(rslt$수술_전_진단명, "[C|c]ancer"), 1, 0))
rslt$수술_전_진단명 <- NULL
# ----- 3.1 데이터 변환 후 탐색적 데이터분석
rslt_list <- partition(skim(rslt))
x_cat_p <- rslt %>%
select(class, rslt_list$factor$skim_variable, rslt_list$character$skim_variable) %>%
gather(variable, value, -class) %>%
group_by(class) %>%
count(variable, value) %>%
ungroup() %>%
ggplot(data = ., aes(x=value, y=n, fill=class)) +
geom_col(position="dodge", width=0.7) +
facet_wrap(~variable, scale = "free", ncol = 4) +
scale_fill_manual(values = c("gray", "red")) +
guides(fill = FALSE, color = FALSE)
plot_grid(y_p, x_cat_p, rel_widths = c(1,3))
# ----- 4. 로지스틱 회귀모형 -----
rslt_iv_df <- rslt %>%
mutate(class = as.integer(class) - 1)
rslt_iv <- create_infotables(data=rslt_iv_df, y='class', bins=10, parallel = T)
rslt_iv$Summary %>%
mutate(Variable = fct_reorder(Variable, IV)) %>%
ggplot(aes(x=Variable, y=IV)) +
geom_col() +
coord_flip()
index_train <- createDataPartition(rslt$class, p = 0.7, list = FALSE)
train_df <- rslt[index_train, ]
test_df  <- rslt[-index_train, ]
## 1
class_glm1 <- glm(class ~ nbp_m_mm_hg + nbp_s_mm_hg + nbp_d_mm_hg, data=train_df,
family = 'binomial')
test_df1 <- test_df %>%
tidypredict_to_column(class_glm1) %>%
mutate(pred_class = ifelse(fit > 0.5, "normal", "hypotension") %>% as.factor)
confusionMatrix(table(test_df$class, test_df1$pred_class))
vif(class_glm1)
## 2
class_glm2 <-  glm(class ~  nbp_s_mm_hg + nbp_d_mm_hg, data=train_df,
family = 'binomial')
test_df2 <- test_df %>%
tidypredict_to_column(class_glm2) %>%
mutate(pred_class = ifelse(fit > 0.5, "normal", "hypotension") %>% as.factor)
confusionMatrix(table(test_df$class, test_df2$pred_class))
vif(class_glm2)
## 3
class_glm3 <- glm(class ~  nbp_s_mm_hg + nbp_d_mm_hg + hr_bpm , data=train_df,
family = 'binomial')
test_df3 <- test_df %>%
tidypredict_to_column(class_glm3) %>%
mutate(pred_class = ifelse(fit > 0.5, "normal", "hypotension") %>% as.factor)
confusionMatrix(table(test_df$class, test_df3$pred_class))
vif(class_glm3)
## 4
class_glm4 <- glm(class ~ nbp_s_mm_hg + nbp_d_mm_hg + hr_bpm + cholecystitis, data=train_df,
family = 'binomial')
test_df4 <- test_df %>%
tidypredict_to_column(class_glm4) %>%
mutate(pred_class = ifelse(fit > 0.5, "normal", "hypotension") %>% as.factor)
confusionMatrix(table(test_df$class, test_df4$pred_class))
vif(class_glm4)
library(tidyverse)
library(caret)
library(tm) # library for text mining
library(extrafont)
library(SnowballC) # stemming(learning, learned => learn)
library(wordcloud)
library(e1071)
library(gmodels)
setwd("./naive_bayse")
setwd("./naive_bayse")
getwd()
setwd("./naive_bayse")
setwd("c:data_mining")
setwd("c:/data_mining")
setwd("./naive_bayse")
sms_raw <- read.csv("sms_spam.csv", encoding="UTF-8")
table(sms_raw$type)
# create train corpus and refine
sms_corpus_clean <- Corpus(VectorSource(sms_raw$text)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
as.character(sms_corpus_clean[[1]])
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=40, random.order=FALSE)
# create document term matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5) # lowfreq = 5, highfreq = Inf
str(sms_freq_words)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0 , 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
# Modeling
## Naive Bayes at e1071
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
m <- naiveBayes(sms_dtm_train, sms_raw_train$type, laplace = 2)
# Evaluation
p <- predict(m, sms_dtm_test, type='class')
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Naive Bayes at caret
### trainControl : Control the computational nuances of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times. repeat = 3 이 안되네..
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl=ctrl)
# Evaluation
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
library(ROCR)
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
sms_test_prob
sms_test_prob[,2]
# prediction() 함수는 예측값에 대한 성능 평과결과가 가지고 있음
# 여기에 performance() 함수를 씌우면 다양한 metric 관점으로 성능 평가를 할 수 있음
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
pred
pred
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_raw <- read.csv("sms_spam.csv", encoding="UTF-8")
sms_raw <- sms_raw[-1072,]
table(sms_raw$type)
# create train corpus and refine
sms_corpus_clean <- Corpus(VectorSource(sms_raw$text)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
as.character(sms_corpus_clean[[1]])
# wordcloud for ham, spam
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=40, random.order=FALSE)
# create document term matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5) # lowfreq = 5, highfreq = Inf
str(sms_freq_words)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0 , 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
# Modeling
## Naive Bayes at e1071
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
m <- naiveBayes(sms_dtm_train, sms_raw_train$type, laplace = 2)
# Evaluation
p <- predict(m, sms_dtm_test, type='class')
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Naive Bayes at caret
### trainControl : Control the computational nuances of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times. repeat = 3 이 안되네..
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl=ctrl)
# Evaluation
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
# Kappa Statistic
# 우연히 맞을 확률을 제외하여 평가
# K = (Pr(a) - Pr(e)) / (1 - Pr(e))
# Pr(a) = 분류기가 실제 일치하게 맞추는 비율
# Pr(e) = 분류기 값과 실제값이 무작위 선택되었다고 가정했을때 두 값 사이의 예상 일치
# Pr(e) = (실제 양성의 비율) * (전체 데이터 비 분류기가 양성으로 분류한 비율) + (실제 음성의 비율) * (전체 데이터 비 분류기가 음성으로 분류한 비율)
# F - 척도
# 모델의 서능을 정밀도와 재현율을 하나의 값으로 평가하고자 할때 사용
# 정밀도와 재현율을 조화평균내서 사용함
# F - 척도 = (2 * 정밀도 * 재현율) / (재현율 + 정밀도)
# 두 메트릭을 하나의 메트릭으로 만들어 사용
# 재현율과 정밀도가 둘 다 높을 때 점수가 좋아짐
# 조화평균 => 두 값이 얼마나 조화로운가?
# 민감도 (sensitivity, true positive rate)
# 관심있는 클래스를 얼마나 잘 분류해 내는지
# sensitivity = (TP) / (TP + FN)
caret::sensitivity(sms_results$predict_type, sms_result$actual_type, positive="spam")
# 특이도 (specificity, true negative rate)
# 다른 클래스를 얼마나 잘 분류해 내는지
# specificity = (TN) / (TN + FP)
caret::specificity(sms_results$predict_type, sms_results$actual_type, negative="ham")
# ROC Curve
# Receiver Operating Characteristic Curve
# 거짓 긍정을 피하면서 참 긍정을 탐지하는 것 사이의 트레이드오프 관계를 확인하기 위함
# y 축 => 참 긍정률 (민감도)
# x 축 => 거짓 긍정률 (1 - 특이도) 즉 거짓도 참이라고 하는 비율
# 임의로 찍었으면(데이터의 비율로 예측값을 내는 경우라면), 웬만하면 같은 비율로 틀리거나 맞기 때문에
# ROC 커브의 y = x 처럼 찍히게 됩니다
# 내가 넣은 값에 따라 참 긍정률 값과 거짓 긍정률 값이 바뀔 텐데,
# 성능이 조금씩 바뀔 텐데, 바뀌는 것으로 시뮬레이션을 해보면
# 연속되는 선으로 표현할 수 있을 것입니다.
# 이 알고리즘이 만들어낸 선이 얼마나 붙어 있는지 확인해 보면
# 이 알고리즘일 얼마나 좋은지 확인해 볼 수 있음
# 테스트 분류기 아래의 면적을 AUC (Area Under the Curve) 라고 함
# AUC 로 트레이드오프 관계를 보는듯..?
# 0.5 <= 1
library(ROCR)
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_raw <- read.csv("sms_spam.csv", encoding="UTF-8")
sms_raw$type %pin% c("All done,")
which(sms_raw$type == "All done, all handed in. Don't know if mega shop in asda counts as celebration but thats what i'm doing!
All done, all handed in. Don't know if mega shop in asda counts as celebration but thats what i'm doing!")
which(!(sms_raw$type %in% c("spam", "ham")))
sms_raw[1072,]
sms_raw <- sms_raw[-1072,]
table(sms_raw$type)
sms_raw <- factor(sms_raw, levels = c("ham", "spam"))
table(sms_raw$type)
sms_raw <- read.csv("sms_spam.csv", encoding="UTF-8")
which(!(sms_raw$type %in% c("spam", "ham")))
sms_raw[1072,]
sms_raw <- sms_raw[-1072,]
sms_raw$type <- factor(sms_raw$type, levels = c("ham", "spam"))
table(sms_raw$type)
sms_corpus_clean <- Corpus(VectorSource(sms_raw$text)) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
as.character(sms_corpus_clean[[1]])
# wordcloud for ham, spam
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=40, random.order=FALSE)
# create document term matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5) # lowfreq = 5, highfreq = Inf
str(sms_freq_words)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0 , 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
# Modeling
## Naive Bayes at e1071
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
m <- naiveBayes(sms_dtm_train, sms_raw_train$type, laplace = 2)
# Evaluation
p <- predict(m, sms_dtm_test, type='class')
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
## Naive Bayes at caret
### trainControl : Control the computational nuances of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times. repeat = 3 이 안되네..
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl=ctrl)
# Evaluation
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
# Kappa Statistic
# 우연히 맞을 확률을 제외하여 평가
# K = (Pr(a) - Pr(e)) / (1 - Pr(e))
# Pr(a) = 분류기가 실제 일치하게 맞추는 비율
# Pr(e) = 분류기 값과 실제값이 무작위 선택되었다고 가정했을때 두 값 사이의 예상 일치
# Pr(e) = (실제 양성의 비율) * (전체 데이터 비 분류기가 양성으로 분류한 비율) + (실제 음성의 비율) * (전체 데이터 비 분류기가 음성으로 분류한 비율)
# F - 척도
# 모델의 서능을 정밀도와 재현율을 하나의 값으로 평가하고자 할때 사용
# 정밀도와 재현율을 조화평균내서 사용함
# F - 척도 = (2 * 정밀도 * 재현율) / (재현율 + 정밀도)
# 두 메트릭을 하나의 메트릭으로 만들어 사용
# 재현율과 정밀도가 둘 다 높을 때 점수가 좋아짐
# 조화평균 => 두 값이 얼마나 조화로운가?
# 민감도 (sensitivity, true positive rate)
# 관심있는 클래스를 얼마나 잘 분류해 내는지
# sensitivity = (TP) / (TP + FN)
caret::sensitivity(sms_results$predict_type, sms_result$actual_type, positive="spam")
# 특이도 (specificity, true negative rate)
# 다른 클래스를 얼마나 잘 분류해 내는지
# specificity = (TN) / (TN + FP)
caret::specificity(sms_results$predict_type, sms_results$actual_type, negative="ham")
# ROC Curve
# Receiver Operating Characteristic Curve
# 거짓 긍정을 피하면서 참 긍정을 탐지하는 것 사이의 트레이드오프 관계를 확인하기 위함
# y 축 => 참 긍정률 (민감도)
# x 축 => 거짓 긍정률 (1 - 특이도) 즉 거짓도 참이라고 하는 비율
# 임의로 찍었으면(데이터의 비율로 예측값을 내는 경우라면), 웬만하면 같은 비율로 틀리거나 맞기 때문에
# ROC 커브의 y = x 처럼 찍히게 됩니다
# 내가 넣은 값에 따라 참 긍정률 값과 거짓 긍정률 값이 바뀔 텐데,
# 성능이 조금씩 바뀔 텐데, 바뀌는 것으로 시뮬레이션을 해보면
# 연속되는 선으로 표현할 수 있을 것입니다.
# 이 알고리즘이 만들어낸 선이 얼마나 붙어 있는지 확인해 보면
# 이 알고리즘일 얼마나 좋은지 확인해 볼 수 있음
# 테스트 분류기 아래의 면적을 AUC (Area Under the Curve) 라고 함
# AUC 로 트레이드오프 관계를 보는듯..?
# 0.5 <= 1
library(ROCR)
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_test_prob[,2]
# prediction() 함수는 예측값에 대한 성능 평과결과가 가지고 있음
# 여기에 performance() 함수를 씌우면 다양한 metric 관점으로 성능 평가를 할 수 있음
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
perf
plot(perf, main = "ROC curve for SMS spam filter", col='blue', lwd=2)
perf.auc <- performance(pred, measure='auc')
perf.auc
perf
