sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # 의미 분석에 큰 의미가 없는 불용어(I, my, me, over)제거
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=10, random.order=FALSE)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
inspect(sms_dtm[1:11, 1:30])
inspect(sms_dtm[1:12, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_freq_words
?findFreqTerms
str(sms_freq_words)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_raw_test <- sms_raw[-train_index,]
inspect(sms_dtm_train)
inspect(sms_dtm_train[1:10, 1:30])
View(sms_dtm_test)
library(e1071)
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_raw_test, type='class')
table(sms_raw_test$type, p)
table(p)
length(sms_raw_test)
p <- predict(m, sms_raw_test$text, type='class')
table(p)
sms_raw_test$text
p <- predict(m, sms_dtm_test, type='class')
table(p)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
library(ROCR)
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_test_prob[,2]
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
sms_test_prob <- predict(m, sms_dtm_test, type='class')
pred <- prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
library(tidyverse)
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
library(ROCR)
setwd("./naive_bayse")
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
table(sms_raw$type) # ham 4812, spam 747
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # ?쓽誘? 遺꾩꽍?뿉 ?겙 ?쓽誘멸? ?뾾?뒗 遺덉슜?뼱(I, my, me, over)?젣嫄?
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=10, random.order=FALSE)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Naive Bayes at caret
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='class')
pred <- prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
sms_test_prob[,2]
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
install.packages("tidyverse")
install.packages("SnowballC")
install.packages("ROCR")
library(tidyverse)
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
install.packages("tm")
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
library(ROCR)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
table(sms_raw$type) # ham 4812, spam 747
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # ?쓽誘? 遺꾩꽍?뿉 ?겙 ?쓽誘멸? ?뾾?뒗 遺덉슜?뼱(I, my, me, over)?젣嫄?
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=10, random.order=FALSE)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Naive Bayes at caret
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='class')
pred <- prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
sms_test_prob[,2]
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
library(caret)
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Naive Bayes at caret
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='class')
pred <- prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
sms_test_prob[,2]
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
length(sms_nb_mod);length(sms_dtm_test);
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
library(tidyverse)
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
library(ROCR)
library(caret)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
table(sms_raw$type) # ham 4812, spam 747
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # ?쓽誘? 遺꾩꽍?뿉 ?겙 ?쓽誘멸? ?뾾?뒗 遺덉슜?뼱(I, my, me, over)?젣嫄?
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=10, random.order=FALSE)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Naive Bayes at caret
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='class')
pred <- prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
sms_test_prob[,2]
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
pred <- prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
pred <- ROCR::prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_test_prob
sms_test_prob <- sms_test_prob[2:3]
pred <- ROCR::prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_test_prob
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
sms_test_prob[,2:3]
sms_test_prob <- sms_test_prob[,2:3]
sms_test_prob
pred <- ROCR::prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
sms_raw_test
sms_raw_test$type
table(sms_raw_test$type)
table(sms_raw$type) # ham 4812, spam 747
sms_raw[!sms_raw$type %in% c('ham', 'spam'), ]
sms_raw[1072,]
sms_raw[1073,]
sms_raw[1074,]sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_raw[1074,]
library(tidyverse)
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
library(ROCR)
library(caret)
# library(wordcloud)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
table(sms_raw$type) # ham 4812, spam 747
sms_raw[!sms_raw$type %in% c('ham', 'spam'), ]
sms_raw <- sms_raw[-1074,]
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # ?쓽誘? 遺꾩꽍?뿉 ?겙 ?쓽誘멸? ?뾾?뒗 遺덉슜?뼱(I, my, me, over)?젣嫄?
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq=50, random.order=FALSE)
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
wordcloud(ham$text, min.freq=50, random.order=FALSE)
wordcloud(spam$text, min.freq=10, random.order=FALSE)
wordcloud(spam$text, max.words=10, random.order=FALSE)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# Naive Bayes at caret
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
sms_test_prob <- sms_test_prob[,2:3]
pred <- ROCR::prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
sms_test_prob
table(sms_raw$type
)
sms_raw <- sms_raw[-1074,]
table(sms_raw$type)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
sms_raw[!sms_raw$type %in% c('ham', 'spam'), ]
sms_raw <- sms_raw[-1072,]
table(sms_raw$type)
library(tidyverse)
library(tm)
library(SnowballC)
library(e1071)
library(gmodels)
library(ROCR)
library(caret)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors=FALSE, encoding='UTF-8')
table(sms_raw$type) # ham 4812, spam 747
sms_raw[!sms_raw$type %in% c('ham', 'spam'), ]
sms_raw <- sms_raw[-1072,]
table(sms_raw$type)
sms_raw$type <- factor(sms_raw$type)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind='en')) %>% # ?쓽誘? 遺꾩꽍?뿉 ?겙 ?쓽誘멸? ?뾾?뒗 遺덉슜?뼱(I, my, me, over)?젣嫄?
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# check
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
as.character(sms_corpus_clean[[1]])
ham <- subset(sms_raw, sms_raw$type=='ham')
ham <- subset(sms_raw, sms_raw$type=='ham')
spam <- subset(sms_raw, sms_raw$type=='spam')
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
inspect(sms_dtm[1:10, 1:30])
sms_freq_words <- findFreqTerms(sms_dtm, 5)
sms_dtm_freq <- sms_dtm[,sms_freq_words]
dim(sms_dtm_freq)
dim(sms_dtm)
# labeling function
convert_counts <- function(x){
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels=c(0, 1), labels=c("Absent", "Present"))
}
# label
sms_dtm_convert <- apply(sms_dtm_freq, 2, convert_counts)
# data partitioning
train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_dtm_train <- sms_dtm_convert[train_index,]
sms_raw_train <- sms_raw[train_index,]
sms_dtm_test <- sms_dtm_convert[-train_index,]
sms_raw_test <- sms_raw[-train_index,]
m <- naiveBayes(sms_dtm_train, sms_raw_train$type)
p <- predict(m, sms_dtm_test, type='class')
table(p)
table(sms_raw_test$type, p)
CrossTable(p, sms_raw_test$type,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
# traincontrol : control the computational nuane of the train function
ctrl <- trainControl(method='cv', number=10) # cross validation 10 times.
sms_nb_mod <- train(sms_dtm_train, sms_raw_train$type, method='nb', trControl = ctrl)
(sms_nb_mod)
sms_nb_pred <- predict(sms_nb_mod, sms_dtm_test)
(cm_nb <- confusionMatrix(sms_nb_pred, sms_raw_test$type, positive='spam'))
sms_test_prob <- predict(m, sms_dtm_test, type='raw')
sms_test_prob
pred <- ROCR::prediction(predictions = sms_test_prob,
labels = sms_raw_test$type)
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
plot(perf, main = "ROC curve for SMS spam filter", col = 'blue', lwd = 2)
perf.auc <- performance(pred, measure='auc')
pred <- ROCR::prediction(predictions = sms_test_prob[,2],
labels = sms_raw_test$type)
perf <- performance(pred, measure = 'tpr', x.measure = 'fpr')
plot(perf, main = "ROC curve for SMS spam filter", col = 'blue', lwd = 2)
perf.auc <- performance(pred, measure='auc')
perf.auc
random_ids <- order(runif(1000))
credit_train <- credit[random_ids[1:500],]
random_ids <- order(runif(1000))
credit_train <- credit[random_ids[1:500],]
credit_validate <- credit[random_ids[501:750],]
credit_test <- credit[random_ids[751:1000],]
folds <- caret::createFolds(credit$default, k=10)
install.packages("C50")
library(C50)
pr_e <- diag(rslt) * rowsum(rslt)
cv_results <- lapply(folds, function(x){
credit_train <- credit[-x,]
credit_test <- credit[x,]
credit_model <- C50::C5.0(default~., data=credit_train)
credit_pred <- predict(credit_model, credit_test)
credit_actual <- credit_test$default
rslt <- table(credit_test$answer, credit_pred)
pr_a <- sum(diag(rslt))
pr_e <- diag(rslt) * rowsum(rslt)
kappa = (pr_a - pr_e) / (1 - pr_e)
return(kappa)
})
